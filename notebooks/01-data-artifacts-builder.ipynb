{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5962731,"sourceType":"datasetVersion","datasetId":3419493},{"sourceId":6568541,"sourceType":"datasetVersion","datasetId":3531266},{"sourceId":6959730,"sourceType":"datasetVersion","datasetId":3997912},{"sourceId":7663855,"sourceType":"datasetVersion","datasetId":4469006},{"sourceId":9004923,"sourceType":"datasetVersion","datasetId":5424936},{"sourceId":14832123,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Phase 1 — Data Assembly (Manifests + Splits)\n\nThis notebook builds canonical CSV **manifests** and **train/val/test splits** for the MRI MVP.\n\n**Key rule:** `/kaggle/working` is *ephemeral*. After any Kaggle runtime restart, rerun this notebook **top-to-bottom** to regenerate artifacts.\n\n## Outputs (written to `/kaggle/working/data_artifacts`)\n### Manifests\n- `manifest_4class_images.csv` — 4-class image paths + labels (folder datasets)\n- `manifest_4class_npz.csv` — NPZ index manifest (external dataset)\n- `manifest_challenge_non_tumor.csv` — near-domain “challenge” pool (non-tumor / OOD-ish)\n\n### Splits\n- `split_train_images.csv`, `split_val_images.csv`, `split_test_images.csv`\n- `split_external_test_npz.csv`\n- `split_challenge_sampled.csv`\n","metadata":{}},{"cell_type":"markdown","source":"## 0) Configuration","metadata":{}},{"cell_type":"code","source":"# CELL: 01_CONFIG — Imports + canonical paths + dataset map (single source of truth)\nfrom pathlib import Path\nfrom datetime import datetime, timezone\nimport json\nimport subprocess\n\nimport numpy as np\nimport pandas as pd\n\nDATASETS = Path(\"/kaggle/input/datasets\")\nOUT = Path(\"/kaggle/working/data_artifacts\")\nOUT.mkdir(parents=True, exist_ok=True)\n\nDATASET_ROOTS = {\n    # 4-class image folders (primary training pool)\n    \"masoudnickparvar/brain-tumor-mri-dataset\": DATASETS/\"masoudnickparvar\"/\"brain-tumor-mri-dataset\",\n    \"sabersakin/brainmri\": DATASETS/\"sabersakin\"/\"brainmri\",\n\n    # 4-class NPZ (external test pool)\n    \"muazalzoubi/brain-tumor-gliomameningiomapituitary-not-tumors\":\n        DATASETS/\"muazalzoubi\"/\"brain-tumor-gliomameningiomapituitary-not-tumors\",\n\n    # near-domain challenge pools (non-tumor / OOD-ish)\n    \"mitangshu11/brain-stroke-mri-images\": DATASETS/\"mitangshu11\"/\"brain-stroke-mri-images\",\n    \"ninadaithal/imagesoasis\": DATASETS/\"ninadaithal\"/\"imagesoasis\",\n    \"trainingdatapro/dicom-brain-dataset\": DATASETS/\"trainingdatapro\"/\"dicom-brain-dataset\",\n}\n\nLABELS = {\n    \"glioma\": 0,\n    \"meningioma\": 1,\n    \"pituitary\": 2,\n    \"notumor\": 3,\n    \"no_tumor\": 3,\n    \"no tumor\": 3,\n}\nIMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n\nprint(\"DATASETS:\", DATASETS, \"exists:\", DATASETS.exists())\nprint(\"OUT:\", OUT, \"exists:\", OUT.exists())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:25:33.173810Z","iopub.execute_input":"2026-02-14T09:25:33.174078Z","iopub.status.idle":"2026-02-14T09:25:34.500246Z","shell.execute_reply.started":"2026-02-14T09:25:33.174052Z","shell.execute_reply":"2026-02-14T09:25:34.499365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -1 /kaggle/input | sed -n '1,200p'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:25:34.501688Z","iopub.execute_input":"2026-02-14T09:25:34.502197Z","iopub.status.idle":"2026-02-14T09:25:34.632695Z","shell.execute_reply.started":"2026-02-14T09:25:34.502168Z","shell.execute_reply":"2026-02-14T09:25:34.631638Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1) Dataset inventory (existence + size)","metadata":{}},{"cell_type":"code","source":"# CELL: 02_DATASET_INVENTORY — Validate dataset roots and print quick size (du -sh)\ndef _du_sh(p: Path) -> str:\n    try:\n        out = subprocess.check_output([\"du\", \"-sh\", str(p)], stderr=subprocess.DEVNULL).decode().strip()\n        return out.split()[0]\n    except Exception:\n        return \"n/a\"\n\nmissing = []\nfor slug, root in DATASET_ROOTS.items():\n    ok = root.exists()\n    size = _du_sh(root) if ok else \"-\"\n    print((\"OK \" if ok else \"MISS\"), f\"{slug:65s}\", \"size:\", f\"{size:>6s}\", \"path:\", root)\n    if ok:\n        # show a few top-level entries (cheap)\n        try:\n            entries = sorted([p.name for p in root.iterdir()])[:8]\n            print(\"   -> top entries:\", entries)\n        except Exception as e:\n            print(\"   -> (could not list entries):\", repr(e))\n    else:\n        missing.append(slug)\n\nassert not missing, f\"Missing required dataset roots: {missing}\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:25:34.634492Z","iopub.execute_input":"2026-02-14T09:25:34.635066Z","iopub.status.idle":"2026-02-14T09:29:57.529604Z","shell.execute_reply.started":"2026-02-14T09:25:34.635019Z","shell.execute_reply":"2026-02-14T09:29:57.528756Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2) Build manifests (canonical CSVs)","metadata":{}},{"cell_type":"code","source":"# CELL: 03_BUILD_MANIFESTS — Write manifest CSVs to /kaggle/working/data_artifacts\nfrom pathlib import Path\n\ndef infer_label(path: Path):\n    parts = [p.lower() for p in path.parts]\n    for k, v in LABELS.items():\n        if k in parts:\n            return k, v\n    return None, None\n\ndef build_image_manifest(dataset_slug: str, root: Path) -> pd.DataFrame:\n    rows = []\n    for p in root.rglob(\"*\"):\n        if not p.is_file():\n            continue\n        if p.suffix.lower() not in IMAGE_EXTS:\n            continue\n        name, lid = infer_label(p)\n        if lid is None:\n            continue\n        rows.append({\"source\": dataset_slug, \"path\": str(p), \"label_name\": name, \"label_id\": lid})\n    return pd.DataFrame(rows)\n\ndef build_npz_manifest(split_name: str, npz_path: Path) -> pd.DataFrame:\n    d = np.load(npz_path, allow_pickle=True)\n    y = d[\"y\"]\n    lids = np.argmax(y, axis=1).astype(int)\n    return pd.DataFrame({\n        \"source\": \"muazalzoubi/brain-tumor-gliomameningiomapituitary-not-tumors\",\n        \"container\": str(npz_path),\n        \"split\": split_name,\n        \"index\": np.arange(len(lids), dtype=int),\n        \"label_id\": lids,\n    })\n\ndef list_images(root: Path, source: str, domain: str) -> pd.DataFrame:\n    rows = []\n    for p in root.rglob(\"*\"):\n        if p.is_file() and p.suffix.lower() in IMAGE_EXTS:\n            rows.append({\"source\": source, \"domain\": domain, \"path\": str(p)})\n    return pd.DataFrame(rows)\n\n# --- 2.1 4-class image manifests (folder datasets)\ndf_img = pd.concat([\n    build_image_manifest(\"masoudnickparvar/brain-tumor-mri-dataset\", DATASET_ROOTS[\"masoudnickparvar/brain-tumor-mri-dataset\"]),\n    build_image_manifest(\"sabersakin/brainmri\", DATASET_ROOTS[\"sabersakin/brainmri\"]),\n], ignore_index=True)\n\np_img = OUT/\"manifest_4class_images.csv\"\ndf_img.to_csv(p_img, index=False)\n\n# --- 2.2 4-class NPZ manifest (external dataset)\nMUAZ = DATASET_ROOTS[\"muazalzoubi/brain-tumor-gliomameningiomapituitary-not-tumors\"]\nprint(\"MUAZ exists:\", MUAZ.exists(), \"->\", MUAZ)\nprint(\"MUAZ files:\", [p.name for p in MUAZ.glob(\"*.npz\")])\n\ndf_npz = pd.concat([\n    build_npz_manifest(\"train\", MUAZ/\"training.npz\"),\n    build_npz_manifest(\"val\", MUAZ/\"validation.npz\"),\n    build_npz_manifest(\"test\", MUAZ/\"test.npz\"),\n], ignore_index=True)\n\np_npz = OUT/\"manifest_4class_npz.csv\"\ndf_npz.to_csv(p_npz, index=False)\n\n# --- 2.3 Challenge manifest (near-domain / non-tumor pools)\ndf_chal = pd.concat([\n    list_images(DATASET_ROOTS[\"mitangshu11/brain-stroke-mri-images\"], \"mitangshu11/brain-stroke-mri-images\", \"stroke\"),\n    list_images(DATASET_ROOTS[\"ninadaithal/imagesoasis\"], \"ninadaithal/imagesoasis\", \"oasis\"),\n    pd.DataFrame([{\n        \"source\": \"trainingdatapro/dicom-brain-dataset\",\n        \"domain\": \"normal_dicom\",\n        \"path\": str(p),\n    } for p in DATASET_ROOTS[\"trainingdatapro/dicom-brain-dataset\"].rglob(\"*\")\n      if p.is_file() and p.suffix.lower() == \".dcm\"])\n], ignore_index=True)\n\np_chal = OUT/\"manifest_challenge_non_tumor.csv\"\ndf_chal.to_csv(p_chal, index=False)\n\n# --- hard assertions + metadata snapshot\nfor p in [p_img, p_npz, p_chal]:\n    assert p.exists() and p.stat().st_size > 0, f\"Failed to write {p}\"\n\nmeta = {\n    \"utc_built_at\": datetime.now(timezone.utc).isoformat(),\n    \"out_dir\": str(OUT),\n    \"rows\": {\n        p_img.name: int(len(df_img)),\n        p_npz.name: int(len(df_npz)),\n        p_chal.name: int(len(df_chal)),\n    },\n}\n(OUT/\"run_metadata_manifests.json\").write_text(json.dumps(meta, indent=2))\nprint(\"OK wrote:\", p_img.name, \"rows=\", len(df_img))\nprint(\"OK wrote:\", p_npz.name, \"rows=\", len(df_npz))\nprint(\"OK wrote:\", p_chal.name, \"rows=\", len(df_chal))\nprint(\"OK manifests present in:\", OUT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:29:57.531015Z","iopub.execute_input":"2026-02-14T09:29:57.531539Z","iopub.status.idle":"2026-02-14T09:32:01.138829Z","shell.execute_reply.started":"2026-02-14T09:29:57.531498Z","shell.execute_reply":"2026-02-14T09:32:01.137977Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3) Verify manifests (counts + label distributions)","metadata":{}},{"cell_type":"code","source":"# CELL: 04_VERIFY_MANIFESTS — Read manifests and print sanity summaries\ndf_img  = pd.read_csv(OUT/\"manifest_4class_images.csv\")\ndf_npz  = pd.read_csv(OUT/\"manifest_4class_npz.csv\")\ndf_chal = pd.read_csv(OUT/\"manifest_challenge_non_tumor.csv\")\n\nprint(\"manifest_4class_images rows:\", len(df_img))\nprint(\"  sources:\\n\", df_img[\"source\"].value_counts())\nprint(\"  labels:\\n\", df_img[\"label_name\"].value_counts())\n\nprint(\"\\nmanifest_4class_npz rows:\", len(df_npz))\nprint(\"  splits:\\n\", df_npz[\"split\"].value_counts())\nprint(\"  label_id:\\n\", df_npz[\"label_id\"].value_counts())\n\nprint(\"\\nmanifest_challenge_non_tumor rows:\", len(df_chal))\nprint(\"  domains:\\n\", df_chal[\"domain\"].value_counts())\n\nprint(\"\\nArtifacts in OUT:\")\nfor p in sorted(OUT.glob(\"*.csv\")):\n    print(\" -\", p.name, f\"({p.stat().st_size/1e6:.2f} MB)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:32:01.140589Z","iopub.execute_input":"2026-02-14T09:32:01.140866Z","iopub.status.idle":"2026-02-14T09:32:01.397006Z","shell.execute_reply.started":"2026-02-14T09:32:01.140833Z","shell.execute_reply":"2026-02-14T09:32:01.396250Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4) Build splits (train/val/test + external test + challenge sample)","metadata":{}},{"cell_type":"code","source":"# CELL: 05_BUILD_SPLITS — Write split CSVs (future-safe groupby apply)\nOUT = Path(\"/kaggle/working/data_artifacts\")\n\ndf_img  = pd.read_csv(OUT/\"manifest_4class_images.csv\")\ndf_npz  = pd.read_csv(OUT/\"manifest_4class_npz.csv\")\ndf_chal = pd.read_csv(OUT/\"manifest_challenge_non_tumor.csv\")\n\nprint(\"loaded:\", len(df_img), \"images;\", len(df_npz), \"npz rows;\", len(df_chal), \"challenge rows\")\n\n# 4.1 image-folder split (stratified by label_id)\nTEST_FRAC = 0.10\nVAL_FRAC  = 0.10  # of remaining after test\nSEED = 42\n\ndf_img = df_img.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n\ntrain_parts, val_parts, test_parts = [], [], []\nfor lid, g in df_img.groupby(\"label_id\"):\n    g = g.sample(frac=1.0, random_state=SEED)\n    n = len(g)\n    n_test = int(round(n * TEST_FRAC))\n    test = g.iloc[:n_test]\n    rem = g.iloc[n_test:]\n    n_val = int(round(len(rem) * VAL_FRAC))\n    val = rem.iloc[:n_val]\n    train = rem.iloc[n_val:]\n    train_parts.append(train)\n    val_parts.append(val)\n    test_parts.append(test)\n\ndf_train = pd.concat(train_parts).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\ndf_val   = pd.concat(val_parts).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\ndf_test  = pd.concat(test_parts).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n\n# 4.2 external test from NPZ: test split only (kept OUT-OF-TRAINING by default)\ndf_external_npz = df_npz[df_npz[\"split\"] == \"test\"].copy().reset_index(drop=True)\n\n# 4.3 challenge sampled (fast iteration; keep small but representative)\nN_PER_DOMAIN = 2000\ncols = [\"source\", \"domain\", \"path\"]\ndf_chal_sample = (\n    df_chal.groupby(\"domain\", group_keys=False)[cols]\n          .apply(lambda g: g.sample(min(len(g), N_PER_DOMAIN), random_state=SEED))\n          .reset_index(drop=True)\n)\n\n# write\np_train = OUT/\"split_train_images.csv\"\np_val   = OUT/\"split_val_images.csv\"\np_test  = OUT/\"split_test_images.csv\"\np_ext   = OUT/\"split_external_test_npz.csv\"\np_chal  = OUT/\"split_challenge_sampled.csv\"\n\ndf_train.to_csv(p_train, index=False)\ndf_val.to_csv(p_val, index=False)\ndf_test.to_csv(p_test, index=False)\ndf_external_npz.to_csv(p_ext, index=False)\ndf_chal_sample.to_csv(p_chal, index=False)\n\nfor p in [p_train, p_val, p_test, p_ext, p_chal]:\n    assert p.exists() and p.stat().st_size > 0, f\"Missing/empty after write: {p}\"\n\nprint(\"\\nImage splits:\")\nprint(\"train:\", len(df_train), \"val:\", len(df_val), \"test:\", len(df_test))\nprint(\"train label dist:\\n\", df_train[\"label_name\"].value_counts())\nprint(\"val label dist:\\n\", df_val[\"label_name\"].value_counts())\nprint(\"test label dist:\\n\", df_test[\"label_name\"].value_counts())\n\nprint(\"\\nExternal NPZ test:\", len(df_external_npz))\nprint(\"npz label_id dist:\\n\", df_external_npz[\"label_id\"].value_counts())\n\nprint(\"\\nChallenge sampled:\", len(df_chal_sample))\nprint(\"domain dist:\\n\", df_chal_sample[\"domain\"].value_counts())\n\nprint(\"\\nOK Split artifacts present.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:32:01.397902Z","iopub.execute_input":"2026-02-14T09:32:01.398623Z","iopub.status.idle":"2026-02-14T09:32:01.815211Z","shell.execute_reply.started":"2026-02-14T09:32:01.398597Z","shell.execute_reply":"2026-02-14T09:32:01.814337Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5) Verify outputs (quick peek)","metadata":{}},{"cell_type":"code","source":"from IPython.display import display\n\n# CELL: 06_VERIFY_OUTPUTS — List artifacts and show sample rows\npaths = [\n    OUT/\"split_train_images.csv\",\n    OUT/\"split_val_images.csv\",\n    OUT/\"split_test_images.csv\",\n    OUT/\"split_external_test_npz.csv\",\n    OUT/\"split_challenge_sampled.csv\",\n]\nprint(\"Artifacts in OUT:\")\nfor p in sorted(OUT.glob(\"*.csv\")):\n    print(\" -\", p.name, f\"({p.stat().st_size/1e6:.2f} MB)\")\n\nprint(\"\\nHeads:\")\nprint(\"\\ntrain head:\")\ndisplay(pd.read_csv(OUT/\"split_train_images.csv\").head(3))\nprint(\"\\nexternal npz head:\")\ndisplay(pd.read_csv(OUT/\"split_external_test_npz.csv\").head(3))\nprint(\"\\nchallenge head:\")\ndisplay(pd.read_csv(OUT/\"split_challenge_sampled.csv\").head(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:32:01.816225Z","iopub.execute_input":"2026-02-14T09:32:01.816531Z","iopub.status.idle":"2026-02-14T09:32:01.906008Z","shell.execute_reply.started":"2026-02-14T09:32:01.816499Z","shell.execute_reply":"2026-02-14T09:32:01.905330Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Notes / Known limitations (honest engineering)\n\n- These datasets are mostly **2D slices** and may not have patient IDs. True patient-level splitting is not possible without metadata.\n- We treat the NPZ dataset as **external test** to measure domain shift (kept out of training by default).\n- The challenge pool is for **validity/OOD behavior checks** (we expect conservative confidence once gating exists).\n","metadata":{}},{"cell_type":"markdown","source":"### 9****9 Health Check","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\n\nOUT = Path(\"/kaggle/working/data_artifacts\")\nprint(\"OUT:\", OUT, \"exists:\", OUT.exists())\n\nexpected = [\n    \"manifest_4class_images.csv\",\n    \"manifest_4class_npz.csv\",\n    \"manifest_challenge_non_tumor.csv\",\n    \"split_train_images.csv\",\n    \"split_val_images.csv\",\n    \"split_test_images.csv\",\n    \"split_external_test_npz.csv\",\n    \"split_challenge_sampled.csv\",\n]\n\nprint(\"\\nFiles:\")\nmissing = []\nfor name in expected:\n    p = OUT/name\n    ok = p.exists() and p.stat().st_size > 0\n    print((\"OK  \" if ok else \"MISS\"), f\"{name:35s}\", \"size:\", (p.stat().st_size if p.exists() else \"-\"))\n    if not ok:\n        missing.append(name)\n\nassert not missing, f\"Missing artifacts: {missing}\"\n\n# Load + validate splits\ndf_train = pd.read_csv(OUT/\"split_train_images.csv\")\ndf_val   = pd.read_csv(OUT/\"split_val_images.csv\")\ndf_test  = pd.read_csv(OUT/\"split_test_images.csv\")\ndf_ext   = pd.read_csv(OUT/\"split_external_test_npz.csv\")\ndf_chal  = pd.read_csv(OUT/\"split_challenge_sampled.csv\")\n\nprint(\"\\nCounts:\")\nprint(\"train:\", len(df_train), \"val:\", len(df_val), \"test:\", len(df_test))\nprint(\"external_npz:\", len(df_ext), \"challenge_sampled:\", len(df_chal))\n\n# Sanity: required columns\nfor name, df, cols in [\n    (\"train\", df_train, {\"path\",\"label_id\",\"label_name\",\"source\"}),\n    (\"val\",   df_val,   {\"path\",\"label_id\",\"label_name\",\"source\"}),\n    (\"test\",  df_test,  {\"path\",\"label_id\",\"label_name\",\"source\"}),\n    (\"ext\",   df_ext,   {\"container\",\"split\",\"index\",\"label_id\",\"source\"}),\n    (\"chal\",  df_chal,  {\"path\",\"domain\",\"source\"}),\n]:\n    miss = cols - set(df.columns)\n    assert not miss, f\"{name} missing columns: {miss}\"\n\n# Sanity: files actually exist on disk (sample a few)\ndef sample_exists(df, col, n=5):\n    s = df[col].sample(min(n, len(df)), random_state=42).tolist()\n    for x in s:\n        assert Path(x).exists(), f\"Missing file on disk: {x}\"\n\nsample_exists(df_train, \"path\", 8)\nsample_exists(df_val, \"path\", 5)\nsample_exists(df_test, \"path\", 5)\n\n# Label sanity\nlabels = sorted(df_train[\"label_id\"].unique().tolist())\nprint(\"\\nLabel ids present in train:\", labels)\nassert set(labels) <= {0,1,2,3}, \"Unexpected label ids\"\n\nprint(\"\\nLabel distribution (train):\\n\", df_train[\"label_name\"].value_counts())\nprint(\"\\nChallenge domains:\\n\", df_chal[\"domain\"].value_counts())\n\nprint(\"\\n✅ DATA PHASE HEALTHCHECK PASSED\")\n\ntrain_set = set(pd.read_csv(OUT/\"split_train_images.csv\")[\"path\"])\nval_set   = set(pd.read_csv(OUT/\"split_val_images.csv\")[\"path\"])\ntest_set  = set(pd.read_csv(OUT/\"split_test_images.csv\")[\"path\"])\n\nassert train_set.isdisjoint(val_set)\nassert train_set.isdisjoint(test_set)\nassert val_set.isdisjoint(test_set)\nprint(\"✅ No path overlap between train/val/test\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T09:32:01.907001Z","iopub.execute_input":"2026-02-14T09:32:01.907254Z","iopub.status.idle":"2026-02-14T09:32:02.077157Z","shell.execute_reply.started":"2026-02-14T09:32:01.907232Z","shell.execute_reply":"2026-02-14T09:32:02.076353Z"}},"outputs":[],"execution_count":null}]}